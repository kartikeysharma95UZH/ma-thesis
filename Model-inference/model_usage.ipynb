{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German Phrase Expansion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kartikeysharma/.pyenv/versions/3.10.3/envs/final_thesis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "# config = PeftConfig.from_pretrained(\"Kartikey95/mt5-xl-phrase-expansion-de\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-xl\")\n",
    "model = PeftModel.from_pretrained(model, \"Kartikey95/mt5-xl-phrase-expansion-de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kartikeysharma/.pyenv/versions/3.10.3/envs/final_thesis/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"google/mt5-xl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Input: Du lernst<SoftSkill>Kunden zu begeistern</SoftSkill> und <SoftSkill_C>mit Freude zu verkaufen</SoftSkill_C>. ->\n",
      "   Output: Du lernst<SoftSkill>Kunden zu begeistern</SoftSkill> und <SoftSkill>mit Freude zu verkaufen</SoftSkill>.\n",
      "\n",
      "\n",
      "2. Input: Sie verfügen über <SoftSkill>unternehmerisches Denken</SoftSkill> sowie <SoftSkill_C>Handeln</SoftSkill_C> ->\n",
      "   Output: Sie verfügen über <SoftSkill>unternehmerisches Denken</SoftSkill> sowie <SoftSkill>unternehmerisches Handeln</SoftSkill>.\n",
      "\n",
      "\n",
      "3. Input: <SoftSkill_C>Kommunikations- </SoftSkill_C> und <SoftSkill>Teamfähigkeit</SoftSkill>\n",
      "   Output: <SoftSkill>Kommunikationsfähigkeit</SoftSkill> und <SoftSkill>Teamfähigkeit</SoftSkill>\n",
      "\n",
      "\n",
      "4. Input: <SoftSkill_C>freundliches</SoftSkill_C><SoftSkill_C>sauberes</SoftSkill_C> und <SoftSkill>motiviertes Auftreten</SoftSkill> ->\n",
      "   Output: <SoftSkill>freundliches Auftreten</SoftSkill> <SoftSkill>sauberes Auftreten</SoftSkill> und <SoftSkill>motiviertes Auftreten</SoftSkill>\n",
      "\n",
      "\n",
      "5. Input: Sie <SoftSkill>arbeiten sehr selbständig</SoftSkill>, <SoftSkill_C>ziel- </SoftSkill_C> und <Soft- Skill_C>kundenorientiert</SoftSkill_C> ->\n",
      "   Output: Sie <SoftSkill>arbeiten sehr selbständig</SoftSkill>, <SoftSkill>arbeiten zielorientiert</SoftSkill> und <SoftSkill>arbeiten kundenorientiert</SoftSkill>\n",
      "\n",
      "\n",
      "6. Input: Als <SoftSkill_C>ausdauernde</SoftSkill_C> und <SoftSkill>proaktiv handelnde Persönlichkeit</SoftSkill> legen Sie grossen Wert auf eine <SoftSkill_C>sicherheitsbewusste</SoftSkill und <SoftSkill>effiziente Arbeitsweise</SoftSkill>. ->\n",
      "   Output: Als <SoftSkill>ausdauernde Persönlichkeit</SoftSkill> und <SoftSkill>proaktiv handelnde Persönlichkeit</SoftSkill> legen Sie grossen Wert auf eine <SoftSkill>sicherheitsbewusste Arbeitsweise</SoftSkill> und <SoftSkill>effiziente Arbeitsweise</SoftSkill>.\n",
      "\n",
      "\n",
      "7. Input: Dipl. Pflegefachfrau/-mann HF/FH, Berufserfahrung im Akutspital <SoftSkill_C>Innovative</SoftSkill_C>, <SoftSkill_C>kooperative</SoftSkill_C> und <SoftSkill>dynamische Persönlichkeit</SoftSkill> <SoftSkill>Freude an selbstständiger Arbeitsweise</SoftSkill> <SoftSkill_C>Hohe Organisations- </SoftSkill_C> und <SoftSkill>Kommunikationsfähigkeit</SoftSkill> ->\n",
      "   Output: Dipl. Pflegefachfrau/-mann HF/FH, Berufserfahrung im Akutspital <SoftSkill>Innovative Persönlichkeit</SoftSkill>, <SoftSkill>kooperative Persönlichkeit</SoftSkill> und <SoftSkill>dynamische Persönlichkeit</SoftSkill> <SoftSkill>Freude an selbstständiger Arbeitsweise</SoftSkill> <SoftSkill>Hohe Organisationsfähigkeit</SoftSkill> und <SoftSkill>Kommunikationsfähigkeit</SoftSkill>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a list of input examples\n",
    "examples = [\n",
    "    'Du lernst<SoftSkill>Kunden zu begeistern</SoftSkill> und <SoftSkill_C>mit Freude zu verkaufen</SoftSkill_C>. ->',\n",
    "    'Sie verfügen über <SoftSkill>unternehmerisches Denken</SoftSkill> sowie <SoftSkill_C>Handeln</SoftSkill_C> ->',\n",
    "    '<SoftSkill_C>Kommunikations- </SoftSkill_C> und <SoftSkill>Teamfähigkeit</SoftSkill>',\n",
    "    '<SoftSkill_C>freundliches</SoftSkill_C><SoftSkill_C>sauberes</SoftSkill_C> und <SoftSkill>motiviertes Auftreten</SoftSkill> ->',\n",
    "    'Sie <SoftSkill>arbeiten sehr selbständig</SoftSkill>, <SoftSkill_C>ziel- </SoftSkill_C> und <Soft- Skill_C>kundenorientiert</SoftSkill_C> ->',\n",
    "    'Als <SoftSkill_C>ausdauernde</SoftSkill_C> und <SoftSkill>proaktiv handelnde Persönlichkeit</SoftSkill> legen Sie grossen Wert auf eine <SoftSkill_C>sicherheitsbewusste</SoftSkill und <SoftSkill>effiziente Arbeitsweise</SoftSkill>. ->',\n",
    "    'Dipl. Pflegefachfrau/-mann HF/FH, Berufserfahrung im Akutspital <SoftSkill_C>Innovative</SoftSkill_C>, <SoftSkill_C>kooperative</SoftSkill_C> und <SoftSkill>dynamische Persönlichkeit</SoftSkill> <SoftSkill>Freude an selbstständiger Arbeitsweise</SoftSkill> <SoftSkill_C>Hohe Organisations- </SoftSkill_C> und <SoftSkill>Kommunikationsfähigkeit</SoftSkill> ->'\n",
    "]\n",
    "\n",
    "for idx, example in enumerate(examples, start=1):       \n",
    "    input_ids = tokenizer.encode(example, return_tensors=\"pt\")\n",
    "    output_ids = model.generate(input_ids=input_ids, max_new_tokens=280)\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    print(f\"{idx}. Input: {example}\\n   Output: {output_text}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German Noun Completion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 2.35k/2.35k [00:00<00:00, 4.55MB/s]\n",
      "Downloading spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 5.11MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.42M/2.42M [00:00<00:00, 3.87MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 2.20k/2.20k [00:00<00:00, 6.13MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 898/898 [00:00<00:00, 2.54MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 3.13G/3.13G [04:34<00:00, 11.4MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 112/112 [00:00<00:00, 253kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer_NC_de = AutoTokenizer.from_pretrained(\"Kartikey95/flan-t5-large-noun-completion-de\")\n",
    "model_NC_de = AutoModelForSeq2SeqLM.from_pretrained(\"Kartikey95/flan-t5-large-noun-completion-de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mittwoch- und Samstagnachmittag --> Mittwochnachmittag und Samstagnachmittag\n",
      "Transaktions- und Managementberatung --> Transaktionsberatung und Managementberatung\n",
      "Personen- und Sozialversicherungen --> Personenversicherungen und Sozialversicherungen\n",
      "Bedienungs- und Servicemanuals --> Bedienungsmanuals und Servicemanuals\n",
      "Umwelt- und Naturwissenschaften --> Umweltwissenschaften und Naturwissenschaften\n"
     ]
    }
   ],
   "source": [
    "# Define a list of input examples\n",
    "examples = [\n",
    "    'Mittwoch- und Samstagnachmittag',\n",
    "    'Transaktions- und Managementberatung',\n",
    "    'Personen- und Sozialversicherungen',\n",
    "    'Bedienungs- und Servicemanuals',\n",
    "    'Umwelt- und Naturwissenschaften'\n",
    "]\n",
    "\n",
    "# Loop through examples, generate outputs, and print input-output pairs\n",
    "for example in examples:\n",
    "    input_ids = tokenizer_NC_de.encode(example, return_tensors=\"pt\")\n",
    "    output_ids = model_NC_de.generate(input_ids=input_ids, max_new_tokens=280)\n",
    "    output_text = tokenizer_NC_de.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"{example} --> {output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English Noun Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 2.35k/2.35k [00:00<00:00, 6.22MB/s]\n",
      "Downloading spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 2.65MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.42M/2.42M [00:00<00:00, 4.33MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 2.20k/2.20k [00:00<00:00, 7.67MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 906/906 [00:00<00:00, 2.35MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 3.13G/3.13G [04:41<00:00, 11.1MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 112/112 [00:00<00:00, 285kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer_NC_en = AutoTokenizer.from_pretrained(\"Kartikey95/flan-t5-large-noun-completion-en\")\n",
    "model_NC_en = AutoModelForSeq2SeqLM.from_pretrained(\"Kartikey95/flan-t5-large-noun-completion-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality and safety requirements --> Quality requirements and safety requirements\n",
      "Expansion and maintenance projects --> Expansion projects and maintenance projects\n",
      "Heating and air conditioning technology --> Heating technology and air conditioning technology\n",
      "Private and corporate clients --> Private clients and corporate clients\n",
      "Purchasing and marketing team --> Purchasing team and marketing team\n"
     ]
    }
   ],
   "source": [
    "# Define a list of input examples\n",
    "examples = [\n",
    "    'Quality and safety requirements',\n",
    "    'Expansion and maintenance projects',\n",
    "    'Heating and air conditioning technology',\n",
    "    'Private and corporate clients',\n",
    "    'Purchasing and marketing team'\n",
    "]\n",
    "\n",
    "# Loop through examples, generate outputs, and print input-output pairs\n",
    "for example in examples:\n",
    "    input_ids = tokenizer_NC_en.encode(example, return_tensors=\"pt\")\n",
    "    output_ids = model_NC_en.generate(input_ids=input_ids, max_new_tokens=280)\n",
    "    output_text = tokenizer_NC_en.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"{example} --> {output_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit ('final_thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a23da5cec2ca06314c8a850333ffd0c512ff89251fad8bc527721334c9dece74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
