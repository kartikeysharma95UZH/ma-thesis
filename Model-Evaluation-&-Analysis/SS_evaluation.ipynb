{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files in directory Bloom:\n",
      "/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/Bloom/summary_metrics_ALL_BLOOM.csv\n",
      "/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/Bloom/summary_metrics_C_BLOOM.csv\n",
      "/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/Bloom/summary_metrics_SENTENCE_BLOOM.csv\n",
      "\n",
      "CSV files in directory FLAN_T5_XXL:\n",
      "/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/FLAN_T5_XXL/summary_metrics_C_FLAN_T5_XXL.csv\n",
      "/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/FLAN_T5_XXL/summary_metrics_ALL_FLAN_T5_XXL.csv\n",
      "/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/FLAN_T5_XXL/summary_metrics_SENTENCE_FLAN_T5_XXL.csv\n",
      "\n",
      "CSV files in directory T5:\n",
      "/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/T5/summary_metrics_C_T5Large.csv\n",
      "/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/T5/summary_metrics_ALL_T5Large.csv\n",
      "/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/T5/summary_metrics_SENTENCE_T5Large.csv\n",
      "\n",
      "CSV files in directory mT5_XL:\n",
      "/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/mT5_XL/summary_metrics_C_mT5_XL.csv\n",
      "/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/mT5_XL/summary_metrics_ALL_mT5_XL.csv\n",
      "/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/mT5_XL/summary_metrics_SENTENCE_mT5_XL.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the main directory\n",
    "main_directory = \"/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/\"\n",
    "\n",
    "# List of subdirectories to iterate through\n",
    "subdirectories = [\"Bloom\", \"FLAN_T5_XXL\", \"T5\", \"mT5_XL\"]\n",
    "all_csv_files = []\n",
    "\n",
    "# Function to find CSV files starting with \"summary_metrics\"\n",
    "def find_summary_metrics_csv_files(directory):\n",
    "    summary_metrics_files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith(\"summary_metrics\") and filename.endswith(\".csv\"):\n",
    "            summary_metrics_files.append(os.path.join(directory, filename))\n",
    "    return summary_metrics_files\n",
    "\n",
    "# Iterate through subdirectories\n",
    "for subdir in subdirectories:\n",
    "    subdir_path = os.path.join(main_directory, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        csv_files = find_summary_metrics_csv_files(subdir_path)\n",
    "        print(f\"CSV files in directory {subdir}:\")\n",
    "        for csv_file in csv_files:\n",
    "            print(csv_file)\n",
    "            all_csv_files.append(csv_file)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/Bloom/summary_metrics_ALL_BLOOM.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/Bloom/summary_metrics_C_BLOOM.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/Bloom/summary_metrics_SENTENCE_BLOOM.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/FLAN_T5_XXL/summary_metrics_C_FLAN_T5_XXL.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/FLAN_T5_XXL/summary_metrics_ALL_FLAN_T5_XXL.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/FLAN_T5_XXL/summary_metrics_SENTENCE_FLAN_T5_XXL.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/T5/summary_metrics_C_T5Large.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/T5/summary_metrics_ALL_T5Large.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/T5/summary_metrics_SENTENCE_T5Large.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/mT5_XL/summary_metrics_C_mT5_XL.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/mT5_XL/summary_metrics_ALL_mT5_XL.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/mT5_XL/summary_metrics_SENTENCE_mT5_XL.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# dfsample = pd.read_csv(\"/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/summary_metrics_C_BLOOM.csv\")\n",
    "# # df = pd.read_csv(\"/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/mT5_XL/summary_metrics_ALL_mT5_XL.csv\")\n",
    "# problem_type_list = dfsample['Problem Type'].tolist() \n",
    "# problem_type_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables for each model and type of C ALL SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL_BLOOM ----> ALL\n",
      "C_BLOOM ----> C\n",
      "SENTENCE_BLOOM ----> SENTENCE\n",
      "C_FLAN_T5_XXL ----> C\n",
      "ALL_FLAN_T5_XXL ----> ALL\n",
      "SENTENCE_FLAN_T5_XXL ----> SENTENCE\n",
      "C_T5Large ----> C\n",
      "ALL_T5Large ----> ALL\n",
      "SENTENCE_T5Large ----> SENTENCE\n",
      "C_mT5_XL ----> C\n",
      "ALL_mT5_XL ----> ALL\n",
      "SENTENCE_mT5_XL ----> SENTENCE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Rouge-L Score (SENTENCE)</th>\n",
       "      <th>Average Levenshtein (SENTENCE)</th>\n",
       "      <th>Cosine Similarity (SENTENCE)</th>\n",
       "      <th>Problem Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>HMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.968930</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.995142</td>\n",
       "      <td>HMDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.983736</td>\n",
       "      <td>3.368421</td>\n",
       "      <td>0.992810</td>\n",
       "      <td>HOWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994611</td>\n",
       "      <td>3.558824</td>\n",
       "      <td>0.996632</td>\n",
       "      <td>MC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.983030</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>MDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.980444</td>\n",
       "      <td>3.264151</td>\n",
       "      <td>0.987359</td>\n",
       "      <td>MWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.990597</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.974783</td>\n",
       "      <td>7.539683</td>\n",
       "      <td>0.988621</td>\n",
       "      <td>OWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.981463</td>\n",
       "      <td>5.133333</td>\n",
       "      <td>0.991043</td>\n",
       "      <td>All Samples</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Rouge-L Score (SENTENCE)  Average Levenshtein (SENTENCE)   \n",
       "0                          1.000000                        1.000000  \\\n",
       "1                          0.968930                        8.500000   \n",
       "2                          0.983736                        3.368421   \n",
       "3                          0.994611                        3.558824   \n",
       "4                          0.983030                        4.000000   \n",
       "5                          0.980444                        3.264151   \n",
       "6                          1.000000                       12.333333   \n",
       "7                          0.974783                        7.539683   \n",
       "8                          0.981463                        5.133333   \n",
       "\n",
       "   Cosine Similarity (SENTENCE) Problem Type  \n",
       "0                      1.000000          HMC  \n",
       "1                      0.995142         HMDC  \n",
       "2                      0.992810         HOWA  \n",
       "3                      0.996632           MC  \n",
       "4                      0.997100          MDC  \n",
       "5                      0.987359          MWA  \n",
       "6                      0.990597         NONE  \n",
       "7                      0.988621          OWA  \n",
       "8                      0.991043  All Samples  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "problem_type_list = ['HMC', 'HMDC', 'HOWA', 'MC', 'MDC', 'MWA', 'NONE', 'OWA', 'All Samples']\n",
    "for file in all_csv_files:\n",
    "    # print(file)\n",
    "    # Extract relevant parts from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    table_name = filename.split(\"_metrics_\")[1].rstrip('.csv')\n",
    "    problem = table_name.split(\"_\")[0]\n",
    "    print(f'{table_name} ----> {problem}')\n",
    "    df = pd.read_csv(file)\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        # Drop the column \"Unnamed: 0\" from the DataFrame\n",
    "        df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "    df['Problem Type'] = problem_type_list\n",
    "    if problem == 'SENTENCE':\n",
    "        new_df = df.iloc[:, [2, 3, 4, 7]]\n",
    "    else:\n",
    "        new_df = df.iloc[:, [2, 3, 4, 5, 8]]\n",
    "\n",
    "    latex_table = new_df.to_latex(index=False)\n",
    "    with open(f'/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/latex_tables/{table_name}.tex', 'w') as file:\n",
    "        file.write(latex_table)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET ALL Metrics for all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_skills_list = []\n",
    "C_skills_list = []\n",
    "SENTENCE_skills_list = []\n",
    "for file in all_csv_files:\n",
    "    filename = os.path.basename(file)\n",
    "    table_name = filename.split(\"_metrics_\")[1].rstrip('.csv')\n",
    "    problem = table_name.split(\"_\")[0]\n",
    "    if problem == \"ALL\":\n",
    "        ALL_skills_list.append(file)\n",
    "    if problem == \"C\":\n",
    "        C_skills_list.append(file)\n",
    "    if problem == \"SENTENCE\":\n",
    "        SENTENCE_skills_list.append(file)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/Bloom/summary_metrics_ALL_BLOOM.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/FLAN_T5_XXL/summary_metrics_ALL_FLAN_T5_XXL.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/T5/summary_metrics_ALL_T5Large.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/mT5_XL/summary_metrics_ALL_mT5_XL.csv']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_skills_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/Bloom/summary_metrics_C_BLOOM.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/FLAN_T5_XXL/summary_metrics_C_FLAN_T5_XXL.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/T5/summary_metrics_C_T5Large.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/mT5_XL/summary_metrics_C_mT5_XL.csv']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_skills_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/Bloom/summary_metrics_SENTENCE_BLOOM.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/FLAN_T5_XXL/summary_metrics_SENTENCE_FLAN_T5_XXL.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/T5/summary_metrics_SENTENCE_T5Large.csv',\n",
       " '/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/mT5_XL/summary_metrics_SENTENCE_mT5_XL.csv']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTENCE_skills_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Rouge-L Score (SENTENCE)</th>\n",
       "      <th>Average Levenshtein (SENTENCE)</th>\n",
       "      <th>Cosine Similarity (SENTENCE)</th>\n",
       "      <th>Problem Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.992181</td>\n",
       "      <td>HMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.956600</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>0.991853</td>\n",
       "      <td>HMDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.983570</td>\n",
       "      <td>3.263158</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>HOWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.969503</td>\n",
       "      <td>11.676471</td>\n",
       "      <td>0.990143</td>\n",
       "      <td>MC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.983409</td>\n",
       "      <td>11.454545</td>\n",
       "      <td>0.991802</td>\n",
       "      <td>MDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.971182</td>\n",
       "      <td>21.358491</td>\n",
       "      <td>0.982437</td>\n",
       "      <td>MWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.933648</td>\n",
       "      <td>14.920635</td>\n",
       "      <td>0.974220</td>\n",
       "      <td>OWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.960309</td>\n",
       "      <td>14.815385</td>\n",
       "      <td>0.983523</td>\n",
       "      <td>All Samples</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Rouge-L Score (SENTENCE)  Average Levenshtein (SENTENCE)   \n",
       "0                          0.933333                       19.000000  \\\n",
       "1                          0.956600                       21.200000   \n",
       "2                          0.983570                        3.263158   \n",
       "3                          0.969503                       11.676471   \n",
       "4                          0.983409                       11.454545   \n",
       "5                          0.971182                       21.358491   \n",
       "6                          1.000000                        0.333333   \n",
       "7                          0.933648                       14.920635   \n",
       "8                          0.960309                       14.815385   \n",
       "\n",
       "   Cosine Similarity (SENTENCE) Problem Type  \n",
       "0                      0.992181          HMC  \n",
       "1                      0.991853         HMDC  \n",
       "2                      0.992453         HOWA  \n",
       "3                      0.990143           MC  \n",
       "4                      0.991802          MDC  \n",
       "5                      0.982437          MWA  \n",
       "6                      1.000000         NONE  \n",
       "7                      0.974220          OWA  \n",
       "8                      0.983523  All Samples  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(SENTENCE_skills_list[0])\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    # Drop the column \"Unnamed: 0\" from the DataFrame\n",
    "    df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df['Problem Type'] = problem_type_list\n",
    "if problem == 'SENTENCE':\n",
    "    new_df = df.iloc[:, [2, 3, 4, 7]]\n",
    "else:\n",
    "    new_df = df.iloc[:, [2, 3, 4, 5, 8]]\n",
    "new_df[new_df['Problem Type'] == 'All Samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Rouge-L Score (SENTENCE)</th>\n",
       "      <th>Average Levenshtein (SENTENCE)</th>\n",
       "      <th>Cosine Similarity (SENTENCE)</th>\n",
       "      <th>Problem Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.960309</td>\n",
       "      <td>14.815385</td>\n",
       "      <td>0.983523</td>\n",
       "      <td>All Samples</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Rouge-L Score (SENTENCE)  Average Levenshtein (SENTENCE)   \n",
       "8                          0.960309                       14.815385  \\\n",
       "\n",
       "   Cosine Similarity (SENTENCE) Problem Type  \n",
       "8                      0.983523  All Samples  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[new_df['Problem Type'] == 'All Samples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables for 'ALL' for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "problem_type_list = ['HMC', 'HMDC', 'HOWA', 'MC', 'MDC', 'MWA', 'NONE', 'OWA', 'All Samples']\n",
    "ALL_skills_across_models = pd.DataFrame()\n",
    "for file in ALL_skills_list:\n",
    "    # Extract relevant parts from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    table_name = filename.split(\"_metrics_\")[1].rstrip('.csv')\n",
    "    model_name1 = table_name.split('ALL_')[1]\n",
    "    problem = table_name.split(\"_\")[0]\n",
    "    # print(f'{table_name} ----> {problem}')\n",
    "    df = pd.read_csv(file)\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        # Drop the column \"Unnamed: 0\" from the DataFrame\n",
    "        df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "    df['Problem Type'] = problem_type_list\n",
    "    df['Model Name'] = model_name1\n",
    "    if problem == 'SENTENCE':\n",
    "        new_df = df.iloc[:, [2, 3, 4, 7, 8]]\n",
    "    else:\n",
    "        new_df = df.iloc[:, [2, 3, 4, 5, 8, 9]]\n",
    "\n",
    "    row_to_add = new_df[new_df['Problem Type'] == 'All Samples']\n",
    "    row_to_add.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Append row_to_add DataFrame to the final_df\n",
    "    ALL_skills_across_models = pd.concat([ALL_skills_across_models, row_to_add], ignore_index=True)\n",
    "\n",
    "ALL_skills_across_models = ALL_skills_across_models.sort_values(by='Weighted Avg. Percentage Skills (ALL)', ascending=False) \n",
    "ALL_skills_across_models.drop(columns=[\"Problem Type\"], inplace=True)\n",
    "\n",
    "latex_table = ALL_skills_across_models.to_latex(index=False)\n",
    "with open(f'/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/latex_tables/ALL_skills_across_models.tex', 'w') as file:\n",
    "    file.write(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables for '_C' for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "problem_type_list = ['HMC', 'HMDC', 'HOWA', 'MC', 'MDC', 'MWA', 'NONE', 'OWA', 'All Samples']\n",
    "C_skills_across_models = pd.DataFrame()\n",
    "for file in C_skills_list:\n",
    "    # Extract relevant parts from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    table_name = filename.split(\"_metrics_\")[1].rstrip('.csv')\n",
    "    model_name1 = table_name.split('C_')[1]\n",
    "    problem = table_name.split(\"_\")[0]\n",
    "    # print(f'{table_name} ----> {problem}')\n",
    "    df = pd.read_csv(file)\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        # Drop the column \"Unnamed: 0\" from the DataFrame\n",
    "        df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "    df['Problem Type'] = problem_type_list\n",
    "    df['Model Name'] = model_name1\n",
    "    if problem == 'SENTENCE':\n",
    "        new_df = df.iloc[:, [2, 3, 4, 7, 8]]\n",
    "    else:\n",
    "        new_df = df.iloc[:, [2, 3, 4, 5, 8, 9]]\n",
    "\n",
    "    row_to_add = new_df[new_df['Problem Type'] == 'All Samples']\n",
    "    row_to_add.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Append row_to_add DataFrame to the final_df\n",
    "    C_skills_across_models = pd.concat([C_skills_across_models, row_to_add], ignore_index=True)\n",
    "\n",
    "C_skills_across_models = C_skills_across_models.sort_values(by='Weighted Avg. Percentage Skills (C)', ascending=False) \n",
    "C_skills_across_models.drop(columns=[\"Problem Type\"], inplace=True)\n",
    "\n",
    "latex_table = C_skills_across_models.to_latex(index=False)\n",
    "with open(f'/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/latex_tables/C_skills_across_models.tex', 'w') as file:\n",
    "    file.write(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables for 'SENTENCE' for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "problem_type_list = ['HMC', 'HMDC', 'HOWA', 'MC', 'MDC', 'MWA', 'NONE', 'OWA', 'All Samples']\n",
    "SENTENCE_skills_across_models = pd.DataFrame()\n",
    "for file in SENTENCE_skills_list:\n",
    "    # Extract relevant parts from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    table_name = filename.split(\"_metrics_\")[1].rstrip('.csv')\n",
    "    model_name1 = table_name.split('SENTENCE_')[1]\n",
    "    problem = table_name.split(\"_\")[0]\n",
    "    # print(f'{table_name} ----> {problem}')\n",
    "    df = pd.read_csv(file)\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        # Drop the column \"Unnamed: 0\" from the DataFrame\n",
    "        df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "    df['Problem Type'] = problem_type_list\n",
    "    df['Model Name'] = model_name1\n",
    "    if problem == 'SENTENCE':\n",
    "        new_df = df.iloc[:, [2, 3, 4, 7, 8]]\n",
    "    else:\n",
    "        new_df = df.iloc[:, [2, 3, 4, 5, 8, 9]]\n",
    "\n",
    "    row_to_add = new_df[new_df['Problem Type'] == 'All Samples']\n",
    "    row_to_add.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Append row_to_add DataFrame to the final_df\n",
    "    SENTENCE_skills_across_models = pd.concat([SENTENCE_skills_across_models, row_to_add], ignore_index=True)\n",
    "\n",
    "SENTENCE_skills_across_models = SENTENCE_skills_across_models.sort_values(by='Average Levenshtein (SENTENCE)', ascending=True) \n",
    "SENTENCE_skills_across_models.drop(columns=[\"Problem Type\"], inplace=True)\n",
    "\n",
    "latex_table = SENTENCE_skills_across_models.to_latex(index=False)\n",
    "with open(f'/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/latex_tables/SENTENCE_skills_across_models.tex', 'w') as file:\n",
    "    file.write(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subproblems -> ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "problem_type_list = ['HMC', 'HMDC', 'HOWA', 'MC', 'MDC', 'MWA', 'NONE', 'OWA', 'All Samples']\n",
    "problem_type_ITER = ['HMC', 'HMDC', 'HOWA', 'MC', 'MDC', 'MWA', 'NONE', 'OWA']\n",
    "\n",
    "for prob_type in problem_type_ITER:\n",
    "    ALL_skills_across_models = pd.DataFrame()\n",
    "    for file in ALL_skills_list:\n",
    "        # Extract relevant parts from the filename\n",
    "        filename = os.path.basename(file)\n",
    "        table_name = filename.split(\"_metrics_\")[1].rstrip('.csv')\n",
    "        model_name1 = table_name.split('ALL_')[1]\n",
    "        problem = table_name.split(\"_\")[0]\n",
    "        # print(f'{table_name} ----> {problem}')\n",
    "        df = pd.read_csv(file)\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            # Drop the column \"Unnamed: 0\" from the DataFrame\n",
    "            df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "        df['Problem Type'] = problem_type_list\n",
    "        df['Model Name'] = model_name1\n",
    "        if problem == 'SENTENCE':\n",
    "            new_df = df.iloc[:, [2, 3, 4, 7, 8]]\n",
    "        else:\n",
    "            new_df = df.iloc[:, [2, 3, 4, 5, 8, 9]]\n",
    "\n",
    "        row_to_add = new_df[new_df['Problem Type'] == prob_type] \n",
    "        row_to_add.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Append row_to_add DataFrame to the final_df\n",
    "        ALL_skills_across_models = pd.concat([ALL_skills_across_models, row_to_add], ignore_index=True)\n",
    "\n",
    "    ALL_skills_across_models = ALL_skills_across_models.sort_values(by='Weighted Avg. Percentage Skills (ALL)', ascending=False) \n",
    "    ALL_skills_across_models.drop(columns=[\"Problem Type\"], inplace=True)\n",
    "\n",
    "\n",
    "    latex_table = ALL_skills_across_models.to_latex(index=False)\n",
    "    with open(f'/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/latex_tables/test/{prob_type}_ALL.tex', 'w') as file:\n",
    "        file.write(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subproblems -> _C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "problem_type_list = ['HMC', 'HMDC', 'HOWA', 'MC', 'MDC', 'MWA', 'NONE', 'OWA', 'All Samples']\n",
    "problem_type_ITER = ['HMC', 'HMDC', 'HOWA', 'MC', 'MDC', 'MWA', 'NONE', 'OWA']\n",
    "\n",
    "for prob_type in problem_type_ITER:\n",
    "    ALL_skills_across_models = pd.DataFrame()\n",
    "    for file in C_skills_list:\n",
    "        # Extract relevant parts from the filename\n",
    "        filename = os.path.basename(file)\n",
    "        table_name = filename.split(\"_metrics_\")[1].rstrip('.csv')\n",
    "        model_name1 = table_name.split('C_')[1]\n",
    "        problem = table_name.split(\"_\")[0]\n",
    "        # print(f'{table_name} ----> {problem}')\n",
    "        df = pd.read_csv(file)\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            # Drop the column \"Unnamed: 0\" from the DataFrame\n",
    "            df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "        df['Problem Type'] = problem_type_list\n",
    "        df['Model Name'] = model_name1\n",
    "        if problem == 'SENTENCE':\n",
    "            new_df = df.iloc[:, [2, 3, 4, 7, 8]]\n",
    "        else:\n",
    "            new_df = df.iloc[:, [2, 3, 4, 5, 8, 9]]\n",
    "\n",
    "        row_to_add = new_df[new_df['Problem Type'] == prob_type] \n",
    "        row_to_add.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Append row_to_add DataFrame to the final_df\n",
    "        ALL_skills_across_models = pd.concat([ALL_skills_across_models, row_to_add], ignore_index=True)\n",
    "\n",
    "    ALL_skills_across_models = ALL_skills_across_models.sort_values(by='Weighted Avg. Percentage Skills (C)', ascending=False) \n",
    "    ALL_skills_across_models.drop(columns=[\"Problem Type\"], inplace=True)\n",
    "\n",
    "\n",
    "    latex_table = ALL_skills_across_models.to_latex(index=False)\n",
    "    with open(f'/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/latex_tables/test/{prob_type}_C.tex', 'w') as file:\n",
    "        file.write(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subproblems --> SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "problem_type_list = ['HMC', 'HMDC', 'HOWA', 'MC', 'MDC', 'MWA', 'NONE', 'OWA', 'All Samples']\n",
    "problem_type_ITER = ['HMC', 'HMDC', 'HOWA', 'MC', 'MDC', 'MWA', 'NONE', 'OWA']\n",
    "\n",
    "for prob_type in problem_type_ITER:\n",
    "    ALL_skills_across_models = pd.DataFrame()\n",
    "    for file in SENTENCE_skills_list:\n",
    "        # Extract relevant parts from the filename\n",
    "        filename = os.path.basename(file)\n",
    "        table_name = filename.split(\"_metrics_\")[1].rstrip('.csv')\n",
    "        model_name1 = table_name.split('SENTENCE_')[1]\n",
    "        problem = table_name.split(\"_\")[0]\n",
    "        # print(f'{table_name} ----> {problem}')\n",
    "        df = pd.read_csv(file)\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            # Drop the column \"Unnamed: 0\" from the DataFrame\n",
    "            df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "        df['Problem Type'] = problem_type_list\n",
    "        df['Model Name'] = model_name1\n",
    "        if problem == 'SENTENCE':\n",
    "            new_df = df.iloc[:, [2, 3, 4, 7, 8]]\n",
    "        else:\n",
    "            new_df = df.iloc[:, [2, 3, 4, 5, 8, 9]]\n",
    "\n",
    "        row_to_add = new_df[new_df['Problem Type'] == prob_type] \n",
    "        row_to_add.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Append row_to_add DataFrame to the final_df\n",
    "        ALL_skills_across_models = pd.concat([ALL_skills_across_models, row_to_add], ignore_index=True)\n",
    "\n",
    "    ALL_skills_across_models = ALL_skills_across_models.sort_values(by='Average Levenshtein (SENTENCE)', ascending=False) \n",
    "    ALL_skills_across_models.drop(columns=[\"Problem Type\"], inplace=True)\n",
    "\n",
    "\n",
    "    latex_table = ALL_skills_across_models.to_latex(index=False)\n",
    "    with open(f'/home/user/ksharma/ks_thesis/ma-thesis/result_evaluation/data_files/latex_tables/test/{prob_type}_SENTENCE.tex', 'w') as file:\n",
    "        file.write(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "from_TARS",
   "language": "python",
   "name": "tars_ipynb_kernel_vsco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
